{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sananda2005/Bank-Marketing-Effectiveness-Prediction/blob/main/Bank_Marketing_Effectiveness_Prediction_Capstone_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOGC-qoyhJeX"
      },
      "source": [
        "# <b><u> Project Title : Predicting the effectiveness of bank marketing campaigns </u></b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y06xIdG26kRF"
      },
      "source": [
        "## <b> Problem Description </b>\n",
        "\n",
        "### The data is related with direct marketing campaigns (phone calls) of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be ('yes') or not ('no') subscribed. The classification goal is to predict if the client will subscribe a term deposit (variable y).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlLxAtlziMbP"
      },
      "source": [
        "## <b> Data Description </b>\n",
        "\n",
        "## <b>Input variables: </b>\n",
        "### <b> Bank Client data: </b>\n",
        "\n",
        "* ### age (numeric)\n",
        "* ### job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
        "* ### marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
        "* ### education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
        "* ### default: has credit in default? (categorical: 'no','yes','unknown')\n",
        "* ### housing: has housing loan? (categorical: 'no','yes','unknown')\n",
        "* ### loan: has personal loan? (categorical: 'no','yes','unknown')\n",
        "\n",
        "### <b> Related with the last contact of the current campaign:</b>\n",
        "* ### contact: contact communication type (categorical: 'cellular','telephone')\n",
        "* ### month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
        "* ### day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
        "* ### duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
        "\n",
        "### <b>Other attributes: </b>\n",
        "* ### campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
        "* ### pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
        "* ### previous: number of contacts performed before this campaign and for this client (numeric)\n",
        "* ### poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
        "\n",
        "\n",
        "### <b>Output variable (desired target):</b>\n",
        "* ### y - has the client subscribed a term deposit? (binary: 'yes','no')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Importing The Libraries**"
      ],
      "metadata": {
        "id": "5GtidVJQX1Gy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import IsolationForest\n"
      ],
      "metadata": {
        "id": "sBB_b3Oyf0dr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Importing and loading our dataset**"
      ],
      "metadata": {
        "id": "OSz-ePVYYhL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mounting the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZNXF3c5Yjy7",
        "outputId": "2ad42dce-2e2c-4ad4-d22e-b6209afd8f5d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reading csv file\n",
        "data= pd.read_csv (\"/content/drive/MyDrive/Bank Marketing Effectiveness Prediction/Copy of bank-full.csv\",sep=';')\n",
        "df=data.copy()"
      ],
      "metadata": {
        "id": "4pJgndaYZAfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "qTim4RD5bc5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "C89P5gBncvU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Understanding of Dataset**"
      ],
      "metadata": {
        "id": "W3jU88F7c6lX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "BfnULLgCbcln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "CPWG4pnGdH-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#detail informations of features\n",
        "df.info()"
      ],
      "metadata": {
        "id": "b9_Ox7zDdXYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Checking null values**"
      ],
      "metadata": {
        "id": "nNmRmbOBd-hQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check null values\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "9s1KFwE5d96r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**There are no null values in the dataset**"
      ],
      "metadata": {
        "id": "YbCJzZ2vegcM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Checking unique and duplicate values**"
      ],
      "metadata": {
        "id": "tOJLxZ7JesP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checking unique values\n",
        "df.nunique()"
      ],
      "metadata": {
        "id": "-Ec9Z0MheweA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking duplicate values\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "dQYS4KL8faxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**There is no duplicate values present in the dataset**"
      ],
      "metadata": {
        "id": "DuvgAlZWgigI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# statistical summary of our data\n",
        "df.describe(include='all')"
      ],
      "metadata": {
        "id": "T3_tsYHdgtQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**DESCRIPTIVE ANALYSIS**\n",
        "###There are two types of variable in our data\n",
        "**1**.**Numerical** \n",
        "\n",
        "**2**.**Catagorical**"
      ],
      "metadata": {
        "id": "lgeeO_E0hEaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**List of Numerical features**"
      ],
      "metadata": {
        "id": "PtTI4y0Fi7Ns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# list of numerical features\n",
        "numerical_feature = list(df.select_dtypes(exclude=['object']))\n",
        "numerical_feature"
      ],
      "metadata": {
        "id": "d-_JdOTditt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**List of Catagorial features**"
      ],
      "metadata": {
        "id": "HpwM2yD-kF3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# list of catagorical features\n",
        "categorical_feature = list(df.select_dtypes(include=['object']))\n",
        "categorical_feature"
      ],
      "metadata": {
        "id": "bC9SvrGskcD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**EXPLORATORY DATA ANALYSIS (EDA)**"
      ],
      "metadata": {
        "id": "Vg6upAGrVCZb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Target Variable**"
      ],
      "metadata": {
        "id": "800L-eruVVJC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Target Variable : y - has the client subscribed a term deposit (binary: 'yes', 'no')**"
      ],
      "metadata": {
        "id": "vcMxsmTJbxAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.y.value_counts()"
      ],
      "metadata": {
        "id": "e_WNxSuOb-3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualising the target variable\n",
        "y_df = sns.countplot(df['y'])"
      ],
      "metadata": {
        "id": "8nb4kRTGcP9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**As We Can See that our data is highly imbalanced, because majority of the data points belong to 'no' class.**"
      ],
      "metadata": {
        "id": "e-4LBh8ndB3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# piechart for percentage of number of subscribers and non-subscribers for term deposit(Traget Variable)\n",
        "labels = 'Not Subscribed', 'Subscribed'\n",
        "sizes = df.y.value_counts()\n",
        "colors = ['black','orange']\n",
        "explode = (0.1,0.0)\n",
        "plt.pie(sizes, explode=explode, labels=labels, colors=colors, \n",
        "        autopct='%1.1f%%',shadow=True,startangle=200)\n",
        "plt.axis('equal')\n",
        "plt.title(\"Proportion of Subscribed & Not Subscribed term Deposit\",fontsize=15)\n",
        "plt.plot()\n",
        "fig=plt.gcf()\n",
        "fig.set_size_inches(8,7)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Tj-DP7RWdEdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**We can see from the above plot that the dataset is imbalanced, where the number of Not-Subscribed class is close to 8 times the number of Subscribed Class.**"
      ],
      "metadata": {
        "id": "yvVv1Jk0sGCq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Univariate Analysis**"
      ],
      "metadata": {
        "id": "0joatmQdsJEk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Let's begin performing EDA on the remaining columns of datapoints.**"
      ],
      "metadata": {
        "id": "Td-iBGPCsQEM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Explore the Categorical Features**"
      ],
      "metadata": {
        "id": "OQDjSbBIVjx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Each variable is represented by a bar graph.\n",
        "\n",
        "#Countplot of categorical features\n",
        "for i in categorical_feature:\n",
        "  print('Column name : ' , i)\n",
        "  print(data[i].value_counts())\n",
        "  plt.figure(figsize=(10,8))\n",
        "  sns.countplot(x = data[i])\n",
        "  plt.xlabel(i)\n",
        "  plt.title(format(i))\n",
        "  plt.xticks(rotation=40)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "0Awyo6xQmdKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Categorical variable's graph representation related to the target variable**"
      ],
      "metadata": {
        "id": "6IL9oreio9a_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Countplot of categorical features\n",
        "for i in categorical_feature:\n",
        "  plt.figure(figsize=(12,8))\n",
        "  sns.countplot(x=data[i] , hue=data['y'])\n",
        "  plt.xlabel(i)\n",
        "  plt.title(format(i))\n",
        "  plt.xticks(rotation=40)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "siWMLxUPo--n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**From the above plots we can analyze that:**\n",
        "\n",
        "####**Top clients are from the 'blue-collar','management', and 'technician' employment types.**\n",
        "####**Retired client has high interest on deposit.**\n",
        "####**In month of March, September, October and December, client show high interest to deposit.**\n",
        "####**In month of may, records are high but client interest ratio is very less.**\n",
        "####**Success rate is highest for student.**\n",
        "####**People whose previous outcome is non-existent have actually subscribed more than any other group of people belonging to previous outcome.**\n",
        "####**Very few clients are contacted who are defaulter.**\n",
        "####**People who are married have subscribed for deposits more than people with any other marital status.**\n",
        "####**Client who has housing loan seems to be not interested much on deposit.**\n"
      ],
      "metadata": {
        "id": "faeLX36-rQ2k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Explore the numerical_feature**"
      ],
      "metadata": {
        "id": "1RvNqNAysM7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#boxplot to show target distribution with respect numerical features\n",
        "plt.figure(figsize=(25,30),facecolor='white')\n",
        "plotnumber=1\n",
        "for i in numerical_feature:\n",
        "    ax = plt.subplot(12,3,plotnumber)\n",
        "    sns.boxplot(x=\"y\", y= df[i],data=df)\n",
        "    plt.title(format(i))\n",
        "    plt.xlabel(i)\n",
        "    plotnumber+=1\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nyXEnePssO8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Since the age feature is not linearly separable for each of the target variables, it is obvious from the above plot that the majority of customers  call are in between 30s to 40s (people who are 33 to 48 years old fall within the 25th to 75th percentiles). Age will therefore have less of an impact on us.**\n",
        "####**As We can see that there are many Outliers in No part As well Yes Part but here our data is Imbalanced so we are keeping this Outliers.**\n"
      ],
      "metadata": {
        "id": "3ZtjdxH_v3p9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Distribution plot of continuous feature\n",
        "plt.figure(figsize=(25,60))\n",
        "plotnumber =1\n",
        "for i in numerical_feature:\n",
        "    ax = plt.subplot(12,3,plotnumber)\n",
        "    sns.distplot(data[i],color ='blue')\n",
        "    plt.title(format(i))\n",
        "    plt.xlabel(i)\n",
        "    plotnumber+=1\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5ncKmt5NvxvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Take-away:**\n",
        "\n",
        "####**It seems age, days distributed normally.**\n",
        "\n",
        "####**Balance, duration, campaign, pdays, and previous are all strongly left-skewed and appear to contain some outliers.**\n",
        "\n",
        "####**The majority of the customers, as shown in the distribution above, are between the ages of 30 and 40.**"
      ],
      "metadata": {
        "id": "gTcyww-ywZuc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Correlation Matrix of the numerical features**"
      ],
      "metadata": {
        "id": "PrYOpKwEwbzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.corr()"
      ],
      "metadata": {
        "id": "sY2hTXZvwUY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Checking for correlation\n",
        "cor_mat=df.corr()\n",
        "fig = plt.figure(figsize=(12,6))\n",
        "sns.heatmap(cor_mat,annot=True, cmap =plt.cm.Reds)"
      ],
      "metadata": {
        "id": "r1nIqfmSxaz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**There is no variable highly correlated to y (Target variable).**"
      ],
      "metadata": {
        "id": "ImuRdd9QyXrI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Data Preprocessing**"
      ],
      "metadata": {
        "id": "nZTg2SGZyaAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "8uRgRKo-yhId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "aw4zJpI11_lS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**We can see there are some binary columns(default, housing, loan) which are object type, we need to convert into numeric value.**\n",
        "\n",
        "####**There are categorical columns as well, but the options are few. These include job, marriage, education, contact, month, and outcome. That must also be transformed into a numerical format.**\n",
        "\n",
        "####**The model can only be fed data when all feature columns have been converted to numeric values.**\n",
        "\n",
        "####**To convert default column into numeric value We can convert the 'yes' values to 1, and the 'no' values to 0.**"
      ],
      "metadata": {
        "id": "iXO9ghsE3p6j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Creating one-hot encoding for non-numeric MARITAL column**\n",
        "\n"
      ],
      "metadata": {
        "id": "VuY0l9em51Gz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "marital_dummies = pd.get_dummies(df['marital'], prefix= 'marital')\n",
        "marital_dummies.head()"
      ],
      "metadata": {
        "id": "t5hjISOB5hi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combine the marital column and marital_dummies\n",
        "pd.concat([df['marital'], marital_dummies], axis = 1).head()"
      ],
      "metadata": {
        "id": "iBDUUcSl6EhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**As we can see, each row has one value of 1, which corresponds to the value in the marital column in the corresponding column.**\n",
        "\n",
        "####**There are three values; if two of the dummy columns' values for a given row are 0, the third column's value must be 1. Redundancy and correlations in features should be eliminated because it can be challenging to determine which feature is most crucial for minimising the overall error.**\n",
        "\n",
        "####**So let's eliminate the column divorced.**"
      ],
      "metadata": {
        "id": "pskix1Pp6Mcb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Elimainating marital_divorced column\n",
        "marital_dummies.drop('marital_divorced', axis =1, inplace = True)\n",
        "marital_dummies.head()"
      ],
      "metadata": {
        "id": "QSTf4d-x6X99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merging marital_dummies into main dataframe\n",
        "df = pd.concat([df, marital_dummies], axis = 1)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Nu3ztv5o6h5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Creating one hot encoding for JOB column**"
      ],
      "metadata": {
        "id": "mscWtr_q6xtJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job_dummies = pd.get_dummies(df['job'], prefix= 'job')\n",
        "job_dummies.head()"
      ],
      "metadata": {
        "id": "IMSIAKdr6sIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Elimainating job_admin column\n",
        "job_dummies.drop('job_admin.', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "Vd61mVf-68kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merging job_dummies into main dataframe\n",
        "df = pd.concat([df, job_dummies], axis=1)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Lh-hs7Tz7I_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Creating one hot encoding for EDUCATION column**"
      ],
      "metadata": {
        "id": "R3unWnsp7aDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "education_dummies = pd.get_dummies(df['education'], prefix = 'education')\n",
        "education_dummies.head()"
      ],
      "metadata": {
        "id": "OiCKnd3_7d1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Elimainating education_primary column\n",
        "education_dummies.drop('education_primary', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "MlVV2P-y7oyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merging education_dummies into main dataframe\n",
        "df = pd.concat([df, education_dummies], axis=1)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "1MmFzWDv7sXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Creating one hot encoding for CONTACT column**"
      ],
      "metadata": {
        "id": "D_GI_oFz8Drd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "contact_dummies = pd.get_dummies(df['contact'], prefix = 'contact')\n",
        "contact_dummies.head()"
      ],
      "metadata": {
        "id": "IaBaA2lP8FBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Elimainating contact_cellular column\n",
        "contact_dummies.drop('contact_cellular', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "FgUMhq0K8MCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merging contact_dummies into main dataframe\n",
        "df = pd.concat([df, contact_dummies], axis=1)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "DP8BZmdX8SVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Creating one hot encoding for POUTCOME column**"
      ],
      "metadata": {
        "id": "JiikZevq8X37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poutcome_dummies = pd.get_dummies(df['poutcome'], prefix = 'poutcome')\n",
        "poutcome_dummies.head()"
      ],
      "metadata": {
        "id": "Z6HOUKgO8dV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Elimainating poutcome_failure column\n",
        "poutcome_dummies.drop('poutcome_failure', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "72aVNFif8oZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Merging poutcome_dummies into main dataframe\n",
        "df = pd.concat([df, poutcome_dummies], axis=1)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "onEanQn_8rfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**We need to convert some binary columns that represent object types (default, housing, and loan) into numeric values.**\n",
        "####**There are also categorical columns, but there are only a few options. Job,marriage, education, contacts, month, and poutcome are some of them.** **Additionally, that needs to be converted to numerical form. Only after all feature columns have been converted to numeric values can we feed them into the model.**"
      ],
      "metadata": {
        "id": "YSFAhi_GTuPW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Converting month column into numeric value**"
      ],
      "metadata": {
        "id": "DQ9i8CUdUJ3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "months = {'jan':1, 'feb':2, 'mar':3, 'apr':4, 'may':5, 'jun':6, 'jul':7, 'aug':8, 'sep':9, 'oct':10, 'nov':11, 'dec': 12}\n",
        "df['month'] = df['month'].map(months)\n",
        "df['month'].head(5)"
      ],
      "metadata": {
        "id": "tDMlXClUUTRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Changing the default column's value to numeric value  For the default column, we can change the yes values to 1 and the no values to 0. For it, we'll use a lambda function.**"
      ],
      "metadata": {
        "id": "1wv4QM18UmXq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Converting default column into numeric value**"
      ],
      "metadata": {
        "id": "JHotPVBgUzYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['new_default'] = df['default'].apply(lambda row: 1 if row == 'yes' else 0 )\n",
        "df[['default', 'new_default']].head()"
      ],
      "metadata": {
        "id": "c02AigS1U6PB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['pdays'] == -1]['pdays'].count()"
      ],
      "metadata": {
        "id": "mVLCWDLvVH8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['was_contacted'] = df['pdays'].apply(lambda row: 0 if row == -1 else 1)\n",
        "df[['pdays','was_contacted']].head()"
      ],
      "metadata": {
        "id": "JhFTJI_-VLD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Converting loan column into numeric value**"
      ],
      "metadata": {
        "id": "9zzO29ToVZGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['new_loan'] = df['loan'].apply(lambda row: 1 if row == 'yes' else 0)\n",
        "df[['loan', 'new_loan']].head()"
      ],
      "metadata": {
        "id": "OMj2iLKgVbC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Converting housing column into numeric value**"
      ],
      "metadata": {
        "id": "nuICC0yVVnXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['new_housing'] = df['housing'].apply(lambda row : 1 if row == 'yes' else 0)\n",
        "df[['housing', 'new_housing']].head()"
      ],
      "metadata": {
        "id": "ctGHhpKqVhuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Converting target column ‘y’ into numeric value**"
      ],
      "metadata": {
        "id": "BQHGMikKV26X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['y_target'] = df['y'].apply(lambda row: 1 if row == 'yes' else 0)\n",
        "df[['y', 'y_target']].head()"
      ],
      "metadata": {
        "id": "0SzSlFe5V5J-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "CwtC2jW-WDmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Eliminating the columns for age, job, marital, education, default, housing, loan, day, contact, month, duration, poutcome, and y.**"
      ],
      "metadata": {
        "id": "79eLZGgjB_r4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['job', 'education', 'marital', 'default', 'housing', 'loan', 'contact', 'poutcome', 'y','month','duration','age','day'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "uOc-9gC9CGD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "BPMpDWcKCYAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "3b2WAo9bClkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "Bmy4agtpCyma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Removing outliers**"
      ],
      "metadata": {
        "id": "v_S8a4GrC1j6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# removing the outlier using IsolationForest Technique\n",
        "\n",
        "features = df.drop(['y_target'],axis=1)\n",
        "\n",
        "anomaly_filter = IsolationForest(contamination=0.1,n_jobs=-1)\n",
        "anomalies = pd.Series(anomaly_filter.fit_predict(features))\n",
        "df['new_anomaly'] = anomalies\n",
        "df = df[df['new_anomaly']==1].drop(['new_anomaly'],axis=1)"
      ],
      "metadata": {
        "id": "SWWhK93TC9QW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "tk28iotXDqct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Giving values to independent variables\n",
        "X = df.drop('y_target', axis = 1)\n",
        "X.head().T"
      ],
      "metadata": {
        "id": "2IUJgEiwDzXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Giving the values of dependent variables\n",
        "y = df['y_target']\n",
        "y.head()"
      ],
      "metadata": {
        "id": "w8eIhWMNEBKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Oversampling using SMOTE**"
      ],
      "metadata": {
        "id": "V515MFXjEEAQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**SMOTE-**\n",
        "\n",
        "####**'Synthetic Minority Oversampling Technique' (SMOTE) is a statistical technique for increasing the number of cases in your dataset in a balanced way. The component works by generating new instances from existing minority cases that you supply as input**"
      ],
      "metadata": {
        "id": "T4T_CJINEOhZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Over sampling the data using SMOTE\n",
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE\n",
        "sampler = SMOTE()\n",
        "X,y = sampler.fit_resample(X.values, y.values)"
      ],
      "metadata": {
        "id": "zSS-S5ADEVue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "1MpkSmZJEfJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "id": "ciptmXKXEoz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# countplot of dependent column y\n",
        "\n",
        "plt.figure(figsize = (10,8))\n",
        "sns.countplot(x = y)\n",
        "plt.xlabel('Y')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Distribution of Y')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Cnae4OOnE2Vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Model Building**\n",
        "\n",
        "###**Logistic Regression**\n",
        "###**Random Forest Classifier**\n",
        "###**Decision Tree Classifier**\n",
        "###**K-Nearest Neighbors (KNN)**\n",
        "###**XGBoost Classifier**"
      ],
      "metadata": {
        "id": "Fcia21Xrnvdb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Splitting data in Train and Test**"
      ],
      "metadata": {
        "id": "5hl0NWa4FM5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the data using Standard Scaler\n",
        "ss = StandardScaler()\n",
        "x = ss.fit_transform(X)"
      ],
      "metadata": {
        "id": "hzYFpkdQFO9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting the dataset into the training set and test set\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state = 42)\n",
        "\n",
        "#shape of training dataset.\n",
        "print(f'shape of x_train set: {x_train.shape}')\n",
        "\n",
        "#shape of testing dataset.\n",
        "print(f'shape of x_test set: {x_test.shape}')"
      ],
      "metadata": {
        "id": "PFN_tZl_FUmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Implementing Various Machine learning Models**"
      ],
      "metadata": {
        "id": "Cl5uuxpUFb--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**1.Logistic Regression**"
      ],
      "metadata": {
        "id": "_5eC_Su0Fh3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data fitting in Logistic Regression\n",
        "log_reg = LogisticRegression(fit_intercept = True, max_iter = 10000)\n",
        "log_reg.fit(x_train, y_train)\n",
        "\n",
        "#prediction of test data\n",
        "logistic_prediction = log_reg.predict(x_test)\n",
        "\n",
        "# Get the accuracy scores\n",
        "logistic_accuracy = accuracy_score(y_test,logistic_prediction)\n",
        "\n",
        "#Checking the traning accuracy\n",
        "print(\"Training accuracy Score : \",log_reg.score(x_train, y_train))\n",
        "#Checking the testing accuracy\n",
        "print(\"Testing accuracy Score : \",logistic_accuracy )"
      ],
      "metadata": {
        "id": "GjAAl228EIag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(logistic_prediction,y_test))"
      ],
      "metadata": {
        "id": "PnY2-zV8ER4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test,logistic_prediction)\n",
        "f,ax = plt.subplots(figsize=(8,6))\n",
        "sns.heatmap(conf_matrix, annot=True,fmt=\"d\", linewidths=.5, ax=ax )\n",
        "plt.title(\"Confusion Matrix\", fontsize=15)\n",
        "ax.set_yticks(np.arange(conf_matrix.shape[0]) + 0.5, minor=False)\n",
        "ax.set_xticklabels(\"Refused T. Deposits', 'Accepted T. Deposits\")\n",
        "ax.set_yticklabels(['Refused T. Deposits', 'Accepted T. Deposits'], fontsize=10, rotation=360)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SRd8VSzGth6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**ROC AOC Curve for Logistic Regression**"
      ],
      "metadata": {
        "id": "HO11WTmAET2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve,roc_auc_score\n",
        "from sklearn.metrics import auc\n",
        "\n",
        "# getting the roc_score\n",
        "log_reg_probability = log_reg.predict_proba(x_test)[:,1]\n",
        "roc_score = roc_auc_score(y_test, log_reg_probability)\n",
        "print(f'roc_score: {roc_score}')"
      ],
      "metadata": {
        "id": "jGjWkE_kFHy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the roc curve for the model\n",
        "from sklearn.metrics import roc_curve\n",
        "logistic_FPR, logistic_TPR, _ = roc_curve(y_test, log_reg_probability)\n",
        "\n",
        "plt.title('ROC curve of Logistic Regression')\n",
        "plt.xlabel('False Positive Rate (Precision)')\n",
        "plt.ylabel('True Positive Rate (Recall)')\n",
        "plt.plot(logistic_FPR,logistic_TPR)\n",
        "plt.plot((0,1),ls='dashed',color='green')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xHT1McIcFozk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**2) Random Forest Classifier**"
      ],
      "metadata": {
        "id": "Bb2I9iofFyqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data fitting in Random Forest model\n",
        "rf_clf = RandomForestClassifier()\n",
        "rf_clf.fit(x_train, y_train)\n",
        "\n",
        "#prediction of test data\n",
        "rf_prediction = rf_clf.predict(x_test)\n",
        "\n",
        "# Get the accuracy scores\n",
        "rf_accuracy = accuracy_score(y_test,rf_prediction)\n",
        "\n",
        "#Checking the traning accuracy\n",
        "print(\"Training accuracy Score : \",rf_clf.score(x_train, y_train))\n",
        "#Checking the testing accuracy\n",
        "print(\"Testing accuracy Score : \",rf_accuracy )"
      ],
      "metadata": {
        "id": "JQh05lr_F5bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report\n",
        "print(classification_report(rf_prediction,y_test))"
      ],
      "metadata": {
        "id": "HXvkoyXDGWX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Confusion Matrix for Random Forest Classifier**"
      ],
      "metadata": {
        "id": "aP4ztn-yGl5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test,rf_prediction)\n",
        "f,ax = plt.subplots(figsize=(8,6))\n",
        "sns.heatmap(conf_matrix, annot=True,fmt=\"d\", linewidths=.5, ax=ax )\n",
        "plt.title(\"Confusion Matrix\", fontsize=15)\n",
        "ax.set_yticks(np.arange(conf_matrix.shape[0]) + 0.5, minor=False)\n",
        "ax.set_xticklabels(\"Refused T. Deposits', 'Accepted T. Deposits\")\n",
        "ax.set_yticklabels(['Refused T. Deposits', 'Accepted T. Deposits'], fontsize=10, rotation=360)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "IERfFE-wICeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**ROC AOC Curve for Random Forest Classifier**"
      ],
      "metadata": {
        "id": "0P3WG_tUIojf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the roc_score\n",
        "rf_clf_probability = rf_clf.predict_proba(x_test)[:,1]\n",
        "roc_socre=roc_auc_score(y_test, rf_clf_probability)\n",
        "print(f'roc_score: {roc_score}')"
      ],
      "metadata": {
        "id": "rB0JRddNIrPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the roc curve for the model\n",
        "\n",
        "random_forest_FPR, random_forest_TPR,_ = roc_curve(y_test, rf_clf_probability)\n",
        "\n",
        "plt.title('Random Forest Classifier ROC curve')\n",
        "plt.xlabel('FPR (Precision)')\n",
        "plt.ylabel('TPR (Recall)')\n",
        "\n",
        "plt.plot(random_forest_FPR,random_forest_TPR)\n",
        "plt.plot((0,1), ls='dashed',color='green')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XCOGE3cAIxpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Important Feature for Random Forest Classifier**"
      ],
      "metadata": {
        "id": "GBsvxVwqI_8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_clf.feature_importances_"
      ],
      "metadata": {
        "id": "wJONIyKEJCfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features=df.columns\n",
        "importances = rf_clf.feature_importances_\n",
        "indices = np.argsort(importances)"
      ],
      "metadata": {
        "id": "fwMRSgYAJPwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,15))\n",
        "plt.title('Feature Importance')\n",
        "plt.barh(range(len(indices)), importances[indices], color='purple', align='center')\n",
        "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
        "plt.xlabel('Relative Importance')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LiGwza0SJRZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Hyperparameter Tuning**"
      ],
      "metadata": {
        "id": "rwGqjTkuJj7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Hyperparameter tuning using RandomizedSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "param_dict = {\n",
        "     \"n_estimators\":[50,100,200,250],\n",
        "    \"max_depth\":[5,10,15],\n",
        "    \"min_samples_split\":[50,100,150,200],\n",
        "    \"min_samples_leaf\":[40,50,60]}\n",
        "\n",
        "#Creating an instance of the RandomForestClassifier\n",
        "rf_clf = RandomForestClassifier()\n",
        "\n",
        "#random search\n",
        "random_rf = RandomizedSearchCV(estimator=rf_clf,param_distributions=param_dict,cv=5,verbose=2,scoring='roc_auc',n_iter=5,random_state=0)\n",
        "random_rf.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "gRtyZEMNydqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Best estimator for random forest\n",
        "random_rf.best_estimator_"
      ],
      "metadata": {
        "id": "1xxjnPAqRx64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_rf.best_params_"
      ],
      "metadata": {
        "id": "eMAzsLoqbCiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions on test data\n",
        "y_pred = random_rf.predict(x_test)\n",
        "\n",
        "# Calculating accuracy on train and test\n",
        "print(f'Training accuracy Score: {accuracy_score(y_train,random_rf.predict(x_train))}')\n",
        "print(f'Testing accuracy Score: {accuracy_score(y_test,y_pred)}')"
      ],
      "metadata": {
        "id": "stdQoY-4cF8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report\n",
        "print(classification_report(y_pred,y_test))"
      ],
      "metadata": {
        "id": "1BwF7rR2cL-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test,y_pred)\n",
        "f,ax = plt.subplots(figsize=(8,6))\n",
        "sns.heatmap(conf_matrix, annot=True,fmt=\"d\", linewidths=.5, ax=ax )\n",
        "plt.title(\"Confusion Matrix\", fontsize=15)\n",
        "ax.set_yticks(np.arange(conf_matrix.shape[0]) + 0.5, minor=False)\n",
        "ax.set_xticklabels(\"Refused T. Deposits', 'Accepted T. Deposits\")\n",
        "ax.set_yticklabels(['Refused T. Deposits', 'Accepted T. Deposits'], fontsize=16, rotation=360)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GGVxlfN0cO4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**ROC AOC Curve for Random Forest Classifier After Hyperparameric Tuning**"
      ],
      "metadata": {
        "id": "AO-1cPG3ccD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the roc_score after Hyperparamer Tuning\n",
        "random_rf_probability = random_rf.predict_proba(x_test)[:,1]\n",
        "roc_socre=roc_auc_score(y_test, random_rf_probability)\n",
        "print(f'roc_score: {roc_score}')"
      ],
      "metadata": {
        "id": "zUEPxFh-cevO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the roc curve for the model\n",
        "random_forest_FPR, random_forest_TPR,_ =  roc_curve(y_test, random_rf_probability)\n",
        "plt.title('Random Forest Classifier ROC curve After Hyperparamater Tuning')\n",
        "plt.xlabel('False Positive Rate (Precision)')\n",
        "plt.ylabel('True Positive Rate  (Recall)')\n",
        "plt.plot(random_forest_FPR,random_forest_TPR)\n",
        "plt.plot((0,1), ls='dashed',color='green')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z0-uwp_kdSJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**3) Decision Tree**"
      ],
      "metadata": {
        "id": "ObWvfZ66dlQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data fitting in Decision Tree model\n",
        "dec_tree_model = DecisionTreeClassifier()\n",
        "dec_tree_model.fit(x_train, y_train)\n",
        "\n",
        "#prediction of test data\n",
        "Decision_prediction = dec_tree_model.predict(x_test)\n",
        "# Get the accuracy scores\n",
        "decision_accuracy = accuracy_score(y_test,Decision_prediction)\n",
        "\n",
        "#Checking the traning accuracy\n",
        "print(f'Training accuracy Score : {dec_tree_model.score(x_train, y_train)}')\n",
        "# checking the testing accuracy\n",
        "print(f'Testing accuracy score : {decision_accuracy}')"
      ],
      "metadata": {
        "id": "-_a3W2HL4Myo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report\n",
        "print(classification_report(Decision_prediction,y_test))"
      ],
      "metadata": {
        "id": "WU_-RnFP4gH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test,Decision_prediction)\n",
        "f,ax = plt.subplots(figsize=(8,6))\n",
        "sns.heatmap(conf_matrix, annot=True,fmt=\"d\", linewidths=.5,ax=ax)\n",
        "plt.title('Confusion Matrix', fontsize=15)\n",
        "ax.set_yticks(np.arange(conf_matrix.shape[0]) + 0.5, minor=False)\n",
        "ax.set_xticklabels(\"Refused T. Deposits', 'Accepted T. Deposits\")\n",
        "ax.set_yticklabels([\"Refused T. Deposits\", \"Accepted T. Deposits\"],fontsize=10, rotation=360)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "P2nmCyZ66HWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**ROC AOC Curve for Decision Tree**"
      ],
      "metadata": {
        "id": "3uhUkMCm7ktz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the roc_score\n",
        "dec_tree_probability = dec_tree_model.predict_proba(x_test)[:,1]\n",
        "roc_socre=roc_auc_score(y_test, dec_tree_probability)\n",
        "print(f'roc_score: {roc_score}')"
      ],
      "metadata": {
        "id": "kgHbkMOT7mDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the roc curve for the model\n",
        "dec_tree_FPR, dec_tree_TPR,_ =  roc_curve(y_test, dec_tree_probability)\n",
        "plt.title('Decision Tree Classifier of ROC curve')\n",
        "plt.xlabel('False Positive Rate (Precision)')\n",
        "plt.ylabel('True Positive Rate  (Recall)')\n",
        "plt.plot(dec_tree_FPR,dec_tree_TPR)\n",
        "plt.plot((0,1), ls='dashed',color='green')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jpVuPWKk7wKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Important Feature for Decision Tree**"
      ],
      "metadata": {
        "id": "ELISpf4j8RPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dec_tree_model.feature_importances_"
      ],
      "metadata": {
        "id": "Eh2dRQ6m8TuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = df.columns\n",
        "importances = dec_tree_model.feature_importances_\n",
        "indices = np.argsort(importances)"
      ],
      "metadata": {
        "id": "HepvqaCf8zAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,15))\n",
        "plt.title('Feature Importance')\n",
        "plt.barh(range(len(indices)), importances[indices], color='purple', align='center')\n",
        "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
        "plt.xlabel('Relative Importance')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ogg6H8WK9kB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**4) K-Nearest Neighbors (KNN)**"
      ],
      "metadata": {
        "id": "azAQ-09h-HWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data fitting in KNN\n",
        "K_model = KNeighborsClassifier()\n",
        "K_model.fit(x_train, y_train)\n",
        "\n",
        "#prediction of test data\n",
        "K_model_prediction = K_model.predict(x_test)\n",
        "# get the accuracy scores\n",
        "k_model_accuracy = accuracy_score(y_test, K_model_prediction)\n",
        "\n",
        "#Checking the traning accuracy\n",
        "print(f'Training accuracy score : {K_model.score(x_train, y_train)}')\n",
        "# checking the testing accuracy\n",
        "print(f'Testing accuracy score : {k_model_accuracy}')"
      ],
      "metadata": {
        "id": "rJdRHQbq-KE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report\n",
        "print(classification_report(K_model_prediction,y_test))"
      ],
      "metadata": {
        "id": "iXrWxMrGtmsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test,K_model_prediction)\n",
        "f,ax = plt.subplots(figsize=(8,6))\n",
        "sns.heatmap(conf_matrix, annot=True,fmt=\"d\", linewidths=.5,ax=ax)\n",
        "plt.title('Confusion Matrix', fontsize=15)\n",
        "ax.set_yticks(np.arange(conf_matrix.shape[0]) + 0.5, minor=False)\n",
        "ax.set_xticklabels(\"Refused T. Deposits', 'Accepted T. Deposits\")\n",
        "ax.set_yticklabels([\"Refused T. Deposits\", \"Accepted T. Deposits\"],fontsize=10, rotation=360)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wxdzCnehwJtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**ROC AOC Curve for K Neighbors**"
      ],
      "metadata": {
        "id": "Q800tjSHtwQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the roc_score\n",
        "K_model_probability = K_model.predict_proba(x_test)[:,1]\n",
        "roc_socre=roc_auc_score(y_test, K_model_probability)\n",
        "roc_socre"
      ],
      "metadata": {
        "id": "-nDcJj0Pt1ns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the roc curve for the model\n",
        "KNN_FPR, KNN_TPR,_ = roc_curve(y_test, K_model_probability)\n",
        "plt.title('K Neighbors Classifier of ROC curve')\n",
        "plt.xlabel('False Positive Rate (Precision)')\n",
        "plt.ylabel('True Positive Rate  (Recall)')\n",
        "plt.plot(KNN_FPR, KNN_TPR)\n",
        "plt.plot((0,1), ls='dashed',color='green')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "i9oq7Lt_uCTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**5) XG Boost**"
      ],
      "metadata": {
        "id": "QXrNiNZguS7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "# Data fitting in xgboost model\n",
        "XGB_model = xgb.XGBClassifier()\n",
        "XGB_model.fit(x_train, y_train)\n",
        "\n",
        "#prediction of test data\n",
        "XGB_model_prediction = XGB_model.predict(x_test)\n",
        "# get the accuracy scores\n",
        "XGB_model_accuracy = accuracy_score(y_test, XGB_model_prediction)\n",
        "\n",
        "#Checking the traning accuracy\n",
        "print(f'Training accuracy score : {XGB_model.score(x_train, y_train)}')\n",
        "# checking the testing accuracy\n",
        "print(f'Testing accuracy score : {XGB_model_accuracy}')"
      ],
      "metadata": {
        "id": "qyEGEsRHuYGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report\n",
        "print(classification_report(XGB_model_prediction,y_test))"
      ],
      "metadata": {
        "id": "7xfb4z7wujL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test,XGB_model_prediction)\n",
        "f,ax = plt.subplots(figsize=(8,6))\n",
        "sns.heatmap(conf_matrix, annot=True,fmt=\"d\", linewidths=.5,ax=ax)\n",
        "plt.title('Confusion Matrix', fontsize=15)\n",
        "ax.set_yticks(np.arange(conf_matrix.shape[0]) + 0.5, minor=False)\n",
        "ax.set_xticklabels(\"Refused T. Deposits', 'Accepted T. Deposits\")\n",
        "ax.set_yticklabels([\"Refused T. Deposits\", \"Accepted T. Deposits\"],fontsize=10, rotation=360)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8O-3sxJCupwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**ROC AOC Curve for XGBoost Classifier**"
      ],
      "metadata": {
        "id": "Jjf_vTq0u65p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the roc_score\n",
        "\n",
        "Xgb_probability = XGB_model.predict_proba(x_test)[:,1]\n",
        "roc_socre=roc_auc_score(y_test, Xgb_probability)\n",
        "roc_socre"
      ],
      "metadata": {
        "id": "WHaLv_OTvBmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the roc curve for the XGB model\n",
        "XGB_FPR, XGB_TPR,_ = roc_curve(y_test, K_model_probability)\n",
        "plt.title('XG Boost Classifier ROC curve')\n",
        "plt.xlabel('False Positive Rate (Precision)')\n",
        "plt.ylabel('True Positive Rate  (Recall)')\n",
        "plt.plot(XGB_FPR, XGB_TPR)\n",
        "plt.plot((0,1), ls='dashed',color='green')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o4gzlcv0vJpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Important Feature for XG Boost Classifier**"
      ],
      "metadata": {
        "id": "2vzH5HJavVyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "XGB_model.feature_importances_"
      ],
      "metadata": {
        "id": "qqX_UaALvXwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = df.columns\n",
        "importances = XGB_model.feature_importances_\n",
        "indices = np.argsort(importances)"
      ],
      "metadata": {
        "id": "9KL6pMU2vgVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,15))\n",
        "plt.title('Feature Importance')\n",
        "plt.barh(range(len(indices)), importances[indices], color='purple', align='center')\n",
        "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
        "plt.xlabel('Relative Importance')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pEeUtnCsvw1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**roc_auc_score for different classifiers**"
      ],
      "metadata": {
        "id": "KfZLGJ-CwHIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Logistic_Regression score: {roc_auc_score(y_test, log_reg_probability)}')\n",
        "print(f'Random Forest Classifier Score: {roc_auc_score(y_test, random_rf_probability)}')\n",
        "print(f'Decision Tree Score: {roc_auc_score(y_test, dec_tree_probability)}')\n",
        "print(f'XGB Classifier score: {roc_auc_score(y_test, Xgb_probability)}')\n",
        "print(f'KNN Score: {roc_auc_score(y_test, K_model_probability)}')"
      ],
      "metadata": {
        "id": "Et91cdjAy15Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the roc curve of models\n",
        "def graph_roc_curve_multiple(logistic_FPR, logistic_TPR,random_forest_FPR,random_forest_TPR,dec_tree_FPR,dec_tree_TPR, XGB_FPR,XGB_TPR,KNN_FPR,KNN_TPR):\n",
        "    plt.figure(figsize=(7,5))\n",
        "    plt.title('comparing the models on the basis of ROC Curve', fontsize=14)\n",
        "    plt.plot(logistic_FPR, logistic_TPR, label='Logistic Regression (Score = 93.22%)')\n",
        "    plt.plot(random_forest_FPR, random_forest_TPR, label='Random Forest (Score = 92.63%)')\n",
        "    plt.plot(dec_tree_FPR, dec_tree_TPR, label='Decision Tree (Score = 88.95%)')\n",
        "    plt.plot(KNN_FPR, KNN_TPR, label='KNN (Score = 93.28%)')\n",
        "    plt.plot(XGB_FPR, XGB_TPR, label='XGB Classifier (Score = 93.29%)')\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.axis([0, 1, 0, 1])\n",
        "    plt.xlabel('False Positive Rate', fontsize=16)\n",
        "    plt.ylabel('True Positive Rate', fontsize=16)\n",
        "    plt.legend()\n",
        "    \n",
        "graph_roc_curve_multiple(logistic_FPR, logistic_TPR,random_forest_FPR, random_forest_TPR, dec_tree_FPR,dec_tree_TPR, XGB_FPR,XGB_TPR, KNN_FPR,KNN_TPR)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qrZDloF9weEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Conclusion**\n",
        "\n",
        "\n",
        "* Blue-collar, management and technician showed maximum interest in subscription.  \n",
        "\n",
        "* Divorce people have no interest in term deposit.\n",
        "\n",
        "* The majority of the customers are between the ages of 30 and 40.\n",
        "\n",
        "* The model can assist in identifying customers based on whether they have made deposits or not.\n",
        "\n",
        "* Most people have home loans, but only a small percentage of them chose term deposits.\n",
        "\n",
        "*  The outcome of the campaign is significantly influenced by the customer's account balance. We can then interact with those customers who have a balanced account balance.\n",
        "\n",
        "* The model can assist in identifying customers based on whether they have made deposits or not.\n",
        "\n",
        "* Instead of wasting time on the wrong customer, the model helps to target the right one.\n",
        "\n",
        "\n",
        "* After implementating all the ML models We get maximum accuracy and ROC-AUC score in XGboost. So we can conclude that it is the best model for us.\n"
      ],
      "metadata": {
        "id": "ahZbYG0Nwhol"
      }
    }
  ]
}